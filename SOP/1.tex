%!TEX root = main.tex

\noindent \textbf{1. How can we design AI assistance that inspires humans' appropriate reliance?}

Many human-AI teams provide humans with "persuasive" AI assistance that improves humans performance but at the expense of humans' overreliance and blind trust towards AI [\citenum{bansal2021}]. This is undesired and unethical, especially in high-stake domains where humans should have the last say.
On the other hand, many work including ours also show that neutral, non-persuasive assistance that dissuade humans from blindly following AI perform no better than persuasive assistance. Thus, I am interested in solving this dilemma.

\sect{research exp}
I worked with Prof. Chenhao Tan at UChicago to design a human-compatible model for case-based decision support.[\citenum{human-compat}]. Our model learns both classification and predicting human perception; we conducted synthetic experiments and human studies on natural image and medical dataset, showing our human-compatible representation leads to better decision support performance than traditional AI representations.



% \subsect{class that motivated me}
% At UChicago, through Dr. Chenhao Tan's course in Human-Center Machine Learning I learned of the complexities of human-AI interaction. In high-stake domains like medical diagnosis, full automation of AI is often not desired and humans have to make the final decision. I am intrigued by the problems caused by this limitation, such as generating explanations that are informative and neutral instead of persuasive and deceiving, complementary performance etc. 

% \subsect{direct impact}
% Also, I am motivated by the direct and visible impact in human-centered AI research. My research project [\citenum{human-compat}] has improved crowdworkers' performance on pneumonia diagnosis in chest X-rays, meaning it has the potential to be implemented in real-life medical settings. Such human-related experiments and improvements are very rewarding to me.
% % \\ 


% \subsect{interdisciplinary}
% Finally I enjoy the interdisciplinary aspects of human-centered AI research. 
% My past research in human-compatible AI decision-support involved modeling human perception, so we used triplet annotations, a method from experimental psychology. 
% My current research aims to leverage our human-compatible AI build radiology teaching framework and we are exploring psychology literature in learning and categorization. 
% More generally, human-centered AI revolves around how humans interact with a decision-making entity and thus involves many many different fields like economics, sociology, ethics, legal, etc. 
% An exciting aspect of human-centered AI resarch is learning and utilizing knowledge from multiple fields. 
% \\



