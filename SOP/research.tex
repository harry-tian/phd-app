%!TEX root = main.tex

\sect{A research project I did}


My research journey began with my work with Prof. Chenhao Tan at UChicago, where we designed a human-compatible model for case-based decision support [\citenum{human-compat}]. 
\subsect{research problem description}
In AI explanations, example-based explanations retrieve the nearest neighbors to a test instance, but the similarity metric for retrieval remains understudied. In fact, the metric is often a distance on some AI model embedding, so the retreived examples may not be informative to humans. 
Towards this end, we developed a human-compatible model that learns both classification and human perception judgement. 
Such a model produced represenations more aligned with human similarity, thus providing more effective nearest-neighbor explanations, or case-based decision-support. 

\subsect{my specific contributions}
My contributions include conducting synthetic experiments: using an artificial dataset with controllable features, I ran experiments with varying simulated humans, generated by tuning feature weights, and varying decision boundaries, showing our human-compatible model resulted in better decision-support than ML model baselines. 
With positive results from synthetic experiments, we moved on to real humans. I conducted a human study on a chest X-ray dataset with Prolific crowdworkers, showing our model also provides effective decision support for pneumonia diagnosis. 
\subsect{research outcomes}
The work led to a publication to the Workshop on Human-Machine Collaboration and Teaming in ICML 2022 [\citenum{human-compat}] as well as an under-review submission to a major ML conference.

\subsect{new skills I learned}
Besides technical skills in experiment design, I learned of an unexpected but useful research practice: being flexible in problem formulation and the research process. 
Our initial goal was to design an AI-driven tutorial for radiology training, largely a machine teaching problem. 
However, in our experimentations with modeling human learners, we found that a neural network that learned both classification and human similarity judgement produced an interesting representation, one that encoded patterns from human perception. 
We did not know how to leverage our human-compatible model for teaching, but we thought it may be useful for case-based decision support. 
Thus, from our finding we detoured to a different research problem, showed its usefulness through empirical studies, and now we return to the problem of AI-driven tutorial.



% Of the many research practices I learned, the most important skill to me was to experiment with ideas. Our project started with a general goal of providing better AI assistance and there were too many direction to go, overwhelming at first. But whenever we had the smallest idea, we would run experiments to simulate human. These incremental ideas with experiment trials eventually led an observation that models learning human perception could produce representations that were closer to humans'. More experiment trials led us to believe the represenations can be useful in decision support.

% Another skill is to be flexible and be willing to reshape the problem to be solved. Our initial goal was to design an AI-driven tutorial for radiology residents. In thinking about how to model human learners, we came across literature on AI learning human perception. With many small, incremental ideas and experiments, we found that AI learning human perception produced representations more aligned with humans. But we did not know how this could be useful for teaching, so we detoured to an easier problem of case-based decision support: providing assistance as the test case's nearest-neighbor in the training set using our learned similarity function. After showing our method works for case-based decision support, we return to the problem of teaching humans, with much more foundation to build on.

% From this project I gained technical skills. Besides designing and experimenting AI models, including using pytorch and running experiments with Wandb, I also learned of the complications in conducting human studies and interacting with crowdworkers. For example, instructions should be clear and intuitive. We also needed ways to collect high quality data, so we designed our own attention-checks. I also learned to better visualize and interpret results. (more description)

% More importantly, I also learned of soft skills and different perspective of approaching research. Our work of learning human perception for decision support was a unique one and there was no previous work to build on. Thus we went through many peripherally related papers. Through the process I developed lit review skills: the ability to skim through an academic paper and quickly determine its relevance to our research. I also learned to really broaden my scope in lit review and research as work is very interdisciplinary: human perception and decision support are involved in different subfields of psychology, while our framework is applied to the medical field. 

% Our problem proposal of designing decision-support and training systems is also quite broad and unspecific. Many of our meetings were brainstorming sessions where we would pitch ideas and if one sounded reasonable, we would run simulation experiments on it. This was how we pivoted to learning human perception and joint learning. In short, I learned to not be afraid to throw in ideas and try them out; this sounds trivial but it not easy for me as I have a heavy internal filter and often question myself.


% \subsect{challenges and contributions}
% Our work was the first to combine learning human perception with classification and use the learned representation to assist human decision-making. Thus, there were many unprecedented problems during our work. 
% Our work was a unique project with few preexisting frameworks to build on, so we face many unprecedented problems.
% On the data side, we had to deal with issues on the format of human perception data, inter-annotator agreement, the amount of data to collect, etc; on the model side, we had to decide on our model architecture, which layer's embedding to use, the dimension of the embedding, etc. 
% \\
% I learned of the importance of synthetic experiments. I built a synthetic dataset of digitally-generated insects with controllable features and also simulated human agents by tuning weights on the features; I also generated varying decision buondaries by altering the ground-truth labels. Synthetic experiments allowed us to exhaustively explore our design and hyperparameters and also provided more insignht; for example, our method works better for non-linearly separable distributions. 
% \\
% With positive results from synthetic experiments, we moved on human studies. I conducted a human study on a chest X-ray dataset with Prolific crowdworkers. Compared to an AI that only learns classification, our human-compatible representations provided decision support that led to better performance pneumonia diagnosis. 
% \subsect{unique contributions}
% Working with another Ph.D student, my unique contributions include running synthetic experiments and conducting a human study on a medical dataset. For the synthetic experiment, we build a synthetic dataset of fictional, digitally-generated insects with 2 relevant features and 2 distractor features. By tuning the weights on these 4 features, we build different synthetic human agents. We also generated several datasets with different decision boundaries. Synthetic experiments allowed us to experiment with different hyperparameters, datasets and designs. For the human study, we wrote a survey webapp using Django and deployed it on Prolific. (more description)


% project description

% The project's initial goal was to develop an AI-driven tutorial framework for radiology residents in prostate cancer diagnosis. We started from machine teaching literature and read about how to select teaching examples to teach humans. This requires modeling human students' representation and we learned about modeling human perception judgements in a high-dimensional space. Motivated by AI learning human intuition, we devised a human-compatible model (using a resnet backbone) that learned both a classification task and predicting human perception. By visualizing the representations on a butterfly-moth dataset, we found that our human-compatible embedding, with high classification accuracy and perception prediction accuracy, learned the class decision boundary but was shaped differently than an resnet embedding trained without human perception: crucially, our human-compatible exhibited inter-class information that was not contained in ground-truth labels but rather from human perception data.

% Thus, our model was significant in that it learned human perception while performing well at classification. While this was far from a teaching framework, we realized that such a human-compatible representation learned some form of human similarity function and could be leveraged for decision support: providing assistance from the training data for humans to make decisions. So we steered away from our initial goal and explored using our human-compatible representation for case-based decision support: given a test case, we provide its nearest-neighbor in the training set using our learned similarity function. We conducted experiments on synthetic datasets as well as human studies on a medical dataset and showed our human-compatible representation leads to better decision support performance than a traditional AI representation. (citation)

