%!TEX root = main.tex
\subsection*{Finding My Research Interest in HAI via AI Decision Support}

\sect{undergrad}

My interest in HAI stems from my undergraduate research experiences in machine learning (ML). At an REU program (Research Experiences for Undergraduates) at the University of North Texas, I learned basic ML knowledge and the experience-focused nature of ML. The following year, I attended an REU at the University of Minnesota. Working with Prof. Zhiwei Steven Wu in Differential Privacy (DP), I experimented with hyperparamter optimization methods and found random search to outperform bayesian optimization. I presented my work at a National REU Poster Symposium. 





\sect{uchicago}


Then, I learned about the human side of ML at the predoctoral program at UChicago, working with Prof. Chenhao Tan at the CHAI (Chicago Human-AI) lab. In our first project, we designed a human-compatible model for case-based decision-support
[\citenum{human-compat}]. 
\subsect{research problem summary}
In explainable AI (XAI), example-based explanations retrieve the nearest neighbors to a test instance, but the similarity metric for retrieval is often based on some AI model embedding or ground-truth features, so the retrieved examples may not be informative to humans. 
\subsect{research project summary}
Towards this end, we developed a human-compatible model that learns both image classification and human visual similarity judgment. Such a model produced representations more aligned with human perception, thus providing more effective nearest-neighbor explanations as case-based decision-support.



\subsect{my specific contributions}
To test the potential of our model, I conducted synthetic experiments by building an artificial dataset with controllable features. I ran experiments with different conditions by varying simulated humans, generated by tuning feature weights, and varying decision boundaries, showing our human-compatible model resulted in better decision-support than baselines. We also showed our method's effectiveness with human studies on a natural image dataset. However, our first submission was unconvincing to reviewers as our tasks were too simple and our datasets too small. Thus, I led an additional round of human studies on a much larger chest X-ray dataset with a pneumonia diagnosis task. I recruited Prolific crowdworkers and conducted studies using our web app; results show our model also provides effective decision support for pneumonia diagnosis, highlighting its potential for more complicated, high-stake tasks. 
\subsect{research outcomes}
The work led to a publication to the Workshop on Human-Machine Collaboration and Teaming in ICML 2022 [\citenum{human-compat}] as well as an under-review submission to a major ML conference.


% \subsect{new skills I learned}
% From this work, I experienced the complexities of an entire research project lifecycle and learned many valuable lessons. I learned to be flexible in problem formulation and breaking a large problem into multiple concrete, well-scaled steps. In fact, our initial goal was to design an AI-driven tutorial for radiology training. But this goal was too broad at first, so we decided to first show our method's effectiveness for example-based local explanations, serving as the foundation for the larger problem of radiology training. Another important lesson I learned was that in empirical research should be comprehensive and significant. For our synthetic experiment, I learned to devise numerous ablation studies on variables like feature weights on agents, decision boundaries, dataset size, injected noise. However, mere comprehensiveness was not enough, as the results were unconvincing due to our tasks' lack of complexity and significance: one was an artificial task and the other was classification on butterflies and moths. So I supplemented our experiments with a medical dataset that was larger and resembled real-life medical diagnoses. Positive results on such a more difficult and high-stake task showed much more potential and significance for our method.








% Besides technical skills in experiment design, I learned of an unexpected but useful research practice: being flexible in problem formulation and the research process. 
% Our initial goal was to design an AI-driven tutorial for radiology training, largely a machine teaching problem. 
% However, in our experimentations with modeling human learners, we found that a neural network that learned both classification and human similarity judgement produced an interesting representation, one that encoded patterns from human perception. 
% We did not know how to leverage our human-compatible model for teaching, but we thought it may be useful for case-based decision support. 
% Thus, from our finding we detoured to a different research problem, showed its usefulness through empirical studies, and now we return to the problem of AI-driven tutorial.



% Of the many research practices I learned, the most important skill to me was to experiment with ideas. Our project started with a general goal of providing better AI assistance and there were too many direction to go, overwhelming at first. But whenever we had the smallest idea, we would run experiments to simulate human. These incremental ideas with experiment trials eventually led an observation that models learning human perception could produce representations that were closer to humans'. More experiment trials led us to believe the represenations can be useful in decision support.

% Another skill is to be flexible and be willing to reshape the problem to be solved. Our initial goal was to design an AI-driven tutorial for radiology residents. In thinking about how to model human learners, we came across literature on AI learning human perception. With many small, incremental ideas and experiments, we found that AI learning human perception produced representations more aligned with humans. But we did not know how this could be useful for teaching, so we detoured to an easier problem of case-based decision support: providing assistance as the test case's nearest-neighbor in the training set using our learned similarity function. After showing our method works for case-based decision support, we return to the problem of teaching humans, with much more foundation to build on.

% From this project I gained technical skills. Besides designing and experimenting AI models, including using pytorch and running experiments with Wandb, I also learned of the complications in conducting human studies and interacting with crowdworkers. For example, instructions should be clear and intuitive. We also needed ways to collect high quality data, so we designed our own attention-checks. I also learned to better visualize and interpret results. (more description)

% More importantly, I also learned of soft skills and different perspective of approaching research. Our work of learning human perception for decision support was a unique one and there was no previous work to build on. Thus we went through many peripherally related papers. Through the process I developed lit review skills: the ability to skim through an academic paper and quickly determine its relevance to our research. I also learned to really broaden my scope in lit review and research as work is very interdisciplinary: human perception and decision support are involved in different subfields of psychology, while our framework is applied to the medical field. 

% Our problem proposal of designing decision-support and training systems is also quite broad and unspecific. Many of our meetings were brainstorming sessions where we would pitch ideas and if one sounded reasonable, we would run simulation experiments on it. This was how we pivoted to learning human perception and joint learning. In short, I learned to not be afraid to throw in ideas and try them out; this sounds trivial but it not easy for me as I have a heavy internal filter and often question myself.


% \subsect{challenges and contributions}
% Our work was the first to combine learning human perception with classification and use the learned representation to assist human decision-making. Thus, there were many unprecedented problems during our work. 
% Our work was a unique project with few preexisting frameworks to build on, so we face many unprecedented problems.
% On the data side, we had to deal with issues on the format of human perception data, inter-annotator agreement, the amount of data to collect, etc; on the model side, we had to decide on our model architecture, which layer's embedding to use, the dimension of the embedding, etc. 
% \\
% I learned of the importance of synthetic experiments. I built a synthetic dataset of digitally-generated insects with controllable features and also simulated human agents by tuning weights on the features; I also generated varying decision buondaries by altering the ground-truth labels. Synthetic experiments allowed us to exhaustively explore our design and hyperparameters and also provided more insignht; for example, our method works better for non-linearly separable distributions. 
% \\
% With positive results from synthetic experiments, we moved on human studies. I conducted a human study on a chest X-ray dataset with Prolific crowdworkers. Compared to an AI that only learns classification, our human-compatible representations provided decision support that led to better performance pneumonia diagnosis. 
% \subsect{unique contributions}
% Working with another Ph.D student, my unique contributions include running synthetic experiments and conducting a human study on a medical dataset. For the synthetic experiment, we build a synthetic dataset of fictional, digitally-generated insects with 2 relevant features and 2 distractor features. By tuning the weights on these 4 features, we build different synthetic human agents. We also generated several datasets with different decision boundaries. Synthetic experiments allowed us to experiment with different hyperparameters, datasets and designs. For the human study, we wrote a survey webapp using Django and deployed it on Prolific. (more description)


% project description

% The project's initial goal was to develop an AI-driven tutorial framework for radiology residents in prostate cancer diagnosis. We started from machine teaching literature and read about how to select teaching examples to teach humans. This requires modeling human students' representation and we learned about modeling human perception judgements in a high-dimensional space. Motivated by AI learning human intuition, we devised a human-compatible model (using a resnet backbone) that learned both a classification task and predicting human perception. By visualizing the representations on a butterfly-moth dataset, we found that our human-compatible embedding, with high classification accuracy and perception prediction accuracy, learned the class decision boundary but was shaped differently than an resnet embedding trained without human perception: crucially, our human-compatible exhibited inter-class information that was not contained in ground-truth labels but rather from human perception data.

% Thus, our model was significant in that it learned human perception while performing well at classification. While this was far from a teaching framework, we realized that such a human-compatible representation learned some form of human similarity function and could be leveraged for decision support: providing assistance from the training data for humans to make decisions. So we steered away from our initial goal and explored using our human-compatible representation for case-based decision support: given a test case, we provide its nearest-neighbor in the training set using our learned similarity function. We conducted experiments on synthetic datasets as well as human studies on a medical dataset and showed our human-compatible representation leads to better decision support performance than a traditional AI representation. (citation)

