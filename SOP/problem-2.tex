%!TEX root = main.tex


\noindent \textbf{\\2. AI learning human perception to provide better AI assistance}


% Our model learns to predict human perception, but in general neural networks learning human perception and intuition is a more difficult task than classification. Perception prediction accuracy is low (70-80\%) compared to classification but the exact reason for this is unknown: it could be due to inter-annotation disagreement, randomness in human perception, low-quality annotation, etc. Related work has also primarily focused on visual perception on images and other modalities are less explored. 
As our work showed, AI learning human perception can provide better decisions support performance; I believe in general, incorporating more human knowledge and intution to AI frameworks has potential to provide more effective AI assistance, but many issues remain unsolved in this nascent direction. 
For example, our work focuses on visual perception on images as it is the easiest form of perception for humans; perception for other modalities like audio and text are also important but much more difficult to collect and utilize. The limitations and bounds of AI learning human perception is also unexplored, including the amount of data needed, the format of data (we used triplet annotations), how well neural networks can learn, etc.




% \textbf{(ii) how and when we can achieve human-AI complementary performance} Complementary performance refers to human-AI team performance outperforming human or AI alone. As mentioned, one factor that affects team performance is human agency and reliance on AI. I am also interested in other factors such as human's and AI expertise on the task. I want to explore the limits of human-AI team and when complementary performance is possible.\\






